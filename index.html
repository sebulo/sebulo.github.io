<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<title>Sebastian Loeschcke</title>
	<link href="css/bootstrap.css" rel="stylesheet">
	<link rel="stylesheet" type="text/css" href="css/styles.css">
	<link href="css/fontawesome-all.css" rel="stylesheet">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="icon" href="images/sf_hill_image.png">
</head>
<body data-spy="scroll" data-target=".fixed-top">
	<div class="container hero">
		<div class="intro">
			<div class="hero-grid">
				<div class="hero-text is-revealing is-header">
					<h1 class="name"><strong>Sebastian Loeschcke</strong></h1>
					<h2 class="lead">Ph.D. Student
					<br/>Department of Computer Science, Machine Learning Section
					<br/><a href="https://di.ku.dk/">University of Copenhagen</a> and <a href="https://www.aicentre.dk/">Pioneer Centre for Artificial Intelligence</a></h2>
					<p>
						I work on efficient training of deep learning models, focusing on low-rank methods and quantization.
						I am advised by <a href="https://scholar.google.com/citations?user=2roUPxkAAAAJ&hl=en">Michael J. Kastoryano</a> and
						<a href="https://scholar.google.com/citations?hl=en&user=chD5XxkAAAAJ">Serge Belongie</a>, and supported by the
						<a href="https://ddsa.dk/">Danish Data Science Academy (DDSA)</a>.
						In 2025, I spent six months visiting <a href="http://tensorlab.cms.caltech.edu/users/anima/" target="_blank">Anima Anandkumarâ€™s group</a> at Caltech, and collaborated with
						<a href="https://research.nvidia.com/person/jean-kossaifi" target="_blank">Jean Kossaifi</a> (NVIDIA Research).
						In 2025â€“2026, I completed a six-month internship at Qualcomm AI Research in Amsterdam, working with the Model Efficiency group under the supervision of
						<a href="https://scholar.google.com/citations?user=akNuBBEAAAAJ&hl=en" target="_blank">Markus Nagel</a>.

					</p>
					<div class="link-row">
						<a class="btn" href="mailto:sebastianloeschcke@gmail.com" aria-label="Email"><i class="fab fas fa-envelope"></i></a>
						<a class="btn" href="https://scholar.google.com/citations?user=_aM-ud8AAAAJ&hl=en" aria-label="Google Scholar"><i class="fa fa-graduation-cap"></i></a>
						<a class="btn" href="https://github.com/sebulo/" aria-label="GitHub"><i class="fab fa-github"></i></a>
						<a class="btn" href="https://www.linkedin.com/in/sebastian-loeschcke/" aria-label="LinkedIn"><i class="fab fa-linkedin-in"></i></a>
						<a class="btn" href="https://twitter.com/sloeschcke" aria-label="X"><img class="x-logo" src="images/X_logo.svg" alt="" aria-hidden="true"></a>
						<a class="btn" href="https://bsky.app/profile/sloeschcke.bsky.social" aria-label="Bluesky">
							<img class="x-logo" src="webfonts/bluesky-black.webp" alt="" aria-hidden="true">
						</a>
					</div>
				</div>
				<div class="hero-photo">
					<img class="img-fluid" src="images/sf_hill_image.png" alt="Portrait of Sebastian Loeschcke">
				</div>
			</div>
		</div>
	</div>
	<!-- BLUE bluesky <a class="btn is-revealing is-header" href="https://bsky.app/profile/sloeschcke.bsky.social"><i class="fab fa-butterfly"></i>&nbsp ðŸ¦‹ Bluesky</a> -->
	<!-- <br><br> -->
  
	<!-- <br><br> -->
	 
	<!-- Publications -->

	<div class="container section">
		<h2 class="section-title">Selected Publications</h2>

		<!-- New publication entry for TensorGRaD -->
<div class="row publication">
	<div class="col-lg-4">
	  <img src="images/TensorGRaD.png" alt="TensorGRaD" style="width:100%; height:auto;">
	</div>
  
	<div class="col-lg-8">
	  <p class="title">TensorGRaD: Tensor Gradient&nbsp;Robust&nbsp;Decomposition&nbsp;for&nbsp;Memory-Efficient Neural Operator Training</p>
  
	  <p class="author">
		<strong>Sebastian Loeschcke,</strong>
		<a href="https://github.com/dhpitt">David Pitt</a>,
		<a href="https://www.robertj1.com/">Robert J.&nbsp;George</a>,
		<a href="https://jiawei-zhao.netlify.app/">Jiawei Zhao</a>,
		<a href="https://wdlctc.github.io/">Cheng Luo</a>,
		<a href="https://yuandong-tian.com/">Yuandong Tian</a>,
		<a href="https://jeankossaifi.com/">Jean Kossaifi</a>,
		<a href="https://tensorlab.cms.caltech.edu/users/anima/">Anima Anandkumar</a>
	  </p>
  
	  <p class="publish"><em>arXiv preprint, 2025.</em></p>
  
	  <a class="btn" href="https://github.com/neuraloperator/tensorgrad">
		<i class="fab fa-github"></i>&nbsp;Code
	  </a>
	  <a class="btn" href="https://arxiv.org/abs/2501.02379">
		<i class="fas fa-file-alt"></i>&nbsp;Paper
	  </a>
  
	  <p>
		TensorGRaD factorizes gradient tensors into complementary low-rank and sparse components, reducing optimizer-state memory by up to <em>75 %</em> while matching the accuracy of Adam, even on turbulent Navierâ€“Stokes at&nbsp;Re&nbsp;= 10<sup>5</sup>.
	  </p>
	</div>
  </div>
			<!-- New publication entry for LoQT -->
		<div class="row publication">
			<div class="col-lg-4">
				<img id="loqt-image" src="images/loqt_memory_13b_llama2_rank1024.png" alt="LoQT" onmouseover="switchImage('images/loqt.png')" onmouseout="switchImage('images/loqt_memory_13b_llama2_rank1024.png')">
			</div>
			<div class="col-lg-8">
				<p class="title">LoQT: Low-Rank Adapters for Quantized Pre-Training</p>
				<p class="author"><strong> Sebastian Loeschcke*,</strong>
					<a href="https://www.linkedin.com/in/mads-toftrup-9ba645111/?originalSubdomain=dk">Mads Toftrup*</a>, 
					<a href="https://mkastoryano.com/">Michael J. Kastoryano</a>, 
					<a href="https://sergebelongie.github.io/"> Serge Belongie</a>,
					<a href="https://vesteinn.is/"> VÃ©steinn SnÃ¦bjarnarson</a>
				</p>
				<p class="publish"><em>NeurIPS 2024.</em> <span class="note">*Equal contribution.</span> <span class="badge badge-award">Best Paper Award</span> at <a href="https://icml.cc/virtual/2024/workshop/29972" target="_blank">WANT@ICML</a>.</p>
				<a class="btn" href="https://github.com/sebulo/LoQT">
					<i class="fab fa-github"></i>&nbsp Code</a>					
				<a class="btn" href="https://arxiv.org/abs/2405.16528">
					<i class="fab fas fa-file-alt"></i>&nbsp Paper</a>
				<p>
					LoQT enables efficient quantized pre-training of LLMs with results close to full-rank non-quantized models. It enables pre-training of a 13B LLM on a 24GB GPU without model parallel, checkpointing, or offloading strategies during training.
				</p>
			</div>
		</div>
		
		<script>
			function switchImage(newSrc) {
				document.getElementById("loqt-image").src = newSrc;
			}
		</script>

	<!-- New publication entry for PuTT -->
	<div class="row publication">
		<div class="col-lg-4">
			<img src='gifs/putt.gif' alt="PuTT visualization">
		</div>
	  <div class="col-lg-8">
		<p class="title">Coarse-To-Fine Tensor Trains for Compact Visual Representations</p>
		<p class="author">
		  <strong>Sebastian Loeschcke,</strong>
		  <a href="https://danalaina.github.io/">Dan Wang</a>,
		  <a href="https://www.linkedin.com/in/christian-leth-espensen-01bb86208/">Christian Leth-Espensen</a>,
		  <a href="https://sergebelongie.github.io/">Serge Belongie</a>,
		  <a href="https://mkastoryano.com/">Michael J. Kastoryano</a>,
		  <a href="https://sagiebenaim.github.io/">Sagie Benaim</a>
		</p>
		<p class="publish"><em>ICML 2024.</em></p>
		<a class="btn" href="https://sebulo.github.io/PuTT_website/">
		  <i class="fas fa-globe-asia"></i>&nbsp; Project page</a>
		<a class="btn" href="https://github.com/sebulo/PuTT">
		  <i class="fab fa-github"></i>&nbsp; Code</a>
		<a class="btn" href="https://arxiv.org/abs/2406.04332">
		  <i class="fas fa-file-alt"></i>&nbsp; Paper</a>
		<p>
		  PuTT (Prolongation Upsampling Tensor Train), a method for learning a coarse-to-fine tensor train representation of visual data, excelling in 2D/3D fitting and novel view synthesis, even with noisy or incomplete data.
		</p>
	  </div>
	</div>
	
	
		<div class="row publication">
			<div class="col-lg-4">
				<img id="publication-gif" src='gifs/org_swan.gif' onmouseover="changeGif('gifs/cactus_swan.gif')" onmouseout="changeGif('gifs/org_swan.gif')">
			</div>
		<div class="col-lg-8">
			<p class="title">Text-Driven Stylization of Video Objects</p>
			<p class="author"><strong> Sebastian Loeschcke, </strong>
				<a href="https://sagiebenaim.github.io/"> Sagie Benaim</a>,
        		<a href="https://sergebelongie.github.io/"> Serge Belongie</a>
			</p>
			<p class="publish">ECCV Workshop on AI for Creative Video Editing and Understanding, 2022.<br><span class="badge badge-award">Best Paper Award</span> <span class="badge badge-oral">Oral Presentation</span></p>

			<a class="btn" href="https://sebulo.github.io/Text-Driven-Stylization-of-Video-Objects/">
                <i class="fab fas fa-globe-asia"></i>&nbsp Project page</a>
              <a class="btn" href="https://arxiv.org/abs/2206.12396"> <i class="fab fas fa-file-alt"></i>&nbsp Paper</a>
              <a class="btn" href="https://youtu.be/b19L96jbfdo">
                <i class="fab fa-youtube"></i>&nbsp Video summary</a>              
              <p>
                A method for stylizing video objects in an intuitive and semantic manner following a user-specified text prompt.
              </p>
		</div>
		
	</div>
		<div class="row publication">
			<div class="col-lg-4">
				<img src='files/sax_paa_param_viz.gif'>
			</div>
			<div class="col-lg-8">
				<p class="title">Progressive Parameter Space Visualization for Task-Driven SAX Configuration</p>
				<p class="author"><strong> Sebastian Loeschcke, </strong>
					<a href="https://github.com/Mahog"> Marius HogrÃ¤fer</a>,
        			<a href="https://cs.au.dk/~hjschulz/"> Hans-JÃ¶rg Schulz</a>
				</p>
				<p class="publish"><em>EuroVA</em>, 2020.  <font color="green"><span class="badge badge-oral">Oral Presentation</span></font> </p>
				<a class="btn" href="https://diglib.eg.org/handle/10.2312/eurova20201085/"> <i class="fab fas fa-file-alt"></i>&nbsp Paper</a>
				<p>
					Tool that uses progressive visual analytics to guide users in hyperparameter search for SAX and PAA algorithms.
				</p>
			</div>
		</div>
	<!-- End of publications -->

	
	
	
<!-- OTHER WORK -->
<div class="container section">
	<h2 class="section-title">Other Work</h2>
	<div class="split">
		<div>
			<h3 class="section-subtitle">Talks</h3>
			<ul class="item-list">
				<li>Invited talk "Low-Rank and Quantized Learning" at <strong>UC Santa Barbara</strong>, hosted by <a href="https://web.ece.ucsb.edu/~zhengzhang/">Zheng Zhang</a>, Mar. 2025.</li>
				<li>Invited talk with Serge Belongie at <strong>NVIDIA Research</strong>, presenting <em>LoQT</em>, hosted by <a href="https://www.linkedin.com/in/georg-zitzlsberger/">Georg Zitzlsberger</a>, Nov. 2024.</li>
				<li>Invited talk at the <strong>D3A 2.0 Conference</strong> (Danish Data Science, Digitalization, and AI), October 23, 2024, on <em>Resource-Aware Machine Learning</em>, hosted by Pinar Tozun and Raghavendra Selvan.</li>
				<li>Oral presentation at the <strong>ICML Workshop on Advancing Neural Network Training</strong> (<a href="https://icml.cc/virtual/2024/workshop/29972" target="_blank">WANT@ICML</a>), 2024.</li>
				<li><a href="https://youtu.be/b19L96jbfdo" target="_blank"><em>Text-Driven Stylization of Video Objects</em></a>, oral presentation at the <strong>ECCV Workshop on AI for Creative Video Editing and Understanding</strong>, Tel Aviv, 2022.</li>
				<li><em>Progressive Parameter Space Visualization for Task-Driven SAX Configuration</em>, presented in NorrkÃ¶ping, Sweden, 2020.</li>
			</ul>
		</div>
		<div>
			<h3 class="section-subtitle">Awards</h3>
			<ul class="item-list">
				<li><strong>Best Paper Award</strong> at ICML workshop on Advancing Neural Network Training <a href="https://icml.cc/virtual/2024/workshop/29972" target="_blank">WANT@ICML</a>.</li>
				<li><strong>Best Paper Award</strong>, ECCV Workshop on AI for Creative Video Editing and Understanding, Tel Aviv 2022. <a href="https://twitter.com/cveu_workshop/status/1583012665408258048">Twitter post.</a></li>
				<li>Queen Margrethe II's travel grant. September 2022. <a href="https://nat.au.dk/en/about-the-faculty/news/show/artikel/masters-students-at-nat-receive-queen-margrethe-iis-travel-grant">News article from Aarhus University.</a></li>
				<li>Awarded a <a href="https://ddsa.dk/news/danish-data-science-academy-grants-26-million-dkk-to-16-new-phd-and-postdocs/">Ph.D. scholarship</a> from the <a href="https://ddsa.dk/">Danish Data Science Academy (DDSA)</a>.</li>
			</ul>
		</div>
	</div>
</div>

	

	<script src="js/jquery.min.js"></script> <!-- jQuery for Bootstrap's JavaScript plugins -->
	<script src="js/bootstrap.min.js"></script> <!-- Bootstrap framework -->
	<script src="js/jquery.easing.min.js"></script> <!-- jQuery Easing for smooth scrolling between anchors -->
    <script src="js/swiper.min.js"></script> <!-- Swiper for image and text sliders -->
    <script src="js/jquery.magnific-popup.js"></script> <!-- Magnific Popup for lightboxes -->
	<script src="https://unpkg.com/scrollreveal@4.0.0/dist/scrollreveal.min.js"></script>
	<script>
		function changeGif(newSrc) {
			const gifElement = document.getElementById("publication-gif");
			gifElement.src = newSrc;
		}
	</script>
	<!-- <script src="js/animation.js"></script> -->

</body>
</html>
